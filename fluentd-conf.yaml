apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: kube-system
  labels:
    k8s-app: fluentd-logging
    version: v1
spec:
  selector:
    matchLabels:
      k8s-app: fluentd-logging
      version: v1
  template:
    metadata:
      labels:
        k8s-app: fluentd-logging
        version: v1
    spec:
      tolerations:
        - key: node-role.kubernetes.io/master
          effect: NoSchedule
      containers:
        - name: fluentd
          image: fluent/fluentd-kubernetes-daemonset:v1.12-debian-kafka2-1
          env:
            - name: "FLUENT_KAFKA_BROKERS"
              value: "my-cluster-kafka-bootstrap.kafka.svc:9092"
          resources:
            limits:
              cpu: 500m
              memory: 512Mi
            requests:
              cpu: 500m
              memory: 512Mi
          volumeMounts:
            - name: config-volume
              mountPath: /fluentd/etc
            - name: varlog
              mountPath: /var/log
            - name: varlibdockercontainers
              mountPath: /var/lib/docker/containers
              readOnly: true
      terminationGracePeriodSeconds: 30
      volumes:
        - name: config-volume
          configMap:
            name: fluentd-config
        - name: varlog
          hostPath:
            path: /var/log
        - name: varlibdockercontainers
          hostPath:
            path: /var/lib/docker/containers
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
  namespace: kube-system
  labels:
    k8s-app: fluentd-logging
    version: v1
data:
  fluent.conf: |-
    @include fluent-source.conf
    @include fluent-filter.conf
    @include fluent-match.conf
  fluent-source.conf: |-
    <source>
      @type tail
      read_from_head true
      tag "kubernetes.*"
      path "/var/log/containers/**nodelogger**.log"
      pos_file "/var/log/kubernetes.log.pos"
      <parse>
        @type kubernetes
        @type json
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      </parse>
    </source>

  fluent-filter.conf: |-
    # filter to grep only logs with defined patterns in them
    <filter>
      @type grep
      <regexp>
        key log
        pattern /{"level/
      </regexp>
    </filter>

    # filter to parse the log as proper JSON
    <filter>
      @type parser
      key_name log
      <parse>
        @type json
      </parse>
    </filter>
    
    # filter to bring keys to root level
    <filter>
      @type record_transformer
      enable_ruby
      <record>
        requestId ${record["req"]["id"]}
        sessionId ${record["req"]["anotherId"]}
      </record>

      <record>
        for_remove1 ${record["req"].delete("id")}
        for_remove2 ${record["req"].delete("anotherId")}
      </record>
      
      remove_keys for_remove1,for_remove2
    </filter>

  fluent-match.conf: |-
    # Ignore fluentd logs
    <match kubernetes.var.log.containers.**fluentd**.log>
      @type null
    </match>
    # Ignore kube-system logs
    <match kubernetes.var.log.containers.**kube-system**.log>
      @type null
    </match>
    
    <match kubernetes.**nodelogger**.log>
      @type kafka2

      brokers my-cluster-kafka-bootstrap.kafka.svc:9092

      <buffer topic>
        flush_mode immediate
        #flush_interval 2s
      </buffer>

      topic_key logs
      default_topic logs

      <format>
        @type json
      </format>

    </match>